[[awk-converter]]
= AWK Converter

== Overview

The AWK converter represents a unique approach within the nu-posix converter system. Rather than attempting to translate AWK's complex programming language syntax into Nushell equivalents, this converter takes a pragmatic approach by executing AWK as an external command with proper argument handling and quoting.

The AWK converter is a "sus" (Single Unix Specification) converter that provides a simple way to run AWK commands as external commands within Nu shell. Given AWK's rich feature set and complex syntax, this converter prioritizes compatibility and reliability over native translation.

== Design Philosophy

=== The Translation Challenge

AWK is a complete programming language with sophisticated features that would be extremely difficult to translate accurately to Nushell:

* **Pattern-Action Programming Model**: AWK's fundamental structure of pattern-action pairs
* **Built-in Variables**: `NR`, `NF`, `FS`, `OFS`, `RS`, `ORS`, and many others
* **Associative Arrays**: Dynamic, string-indexed arrays with complex semantics
* **Regular Expression Integration**: Deep integration with pattern matching
* **Field Processing**: Automatic field splitting and variable assignment
* **Control Flow**: Complex loops, conditionals, and function definitions
* **Mathematical Functions**: Extensive built-in mathematical operations

=== External Command Approach

The AWK converter uses the external command approach because:

1. **100% Compatibility**: Preserves all AWK functionality without translation limitations
2. **Simplicity**: Straightforward implementation that's easy to maintain
3. **Reliability**: No risk of translation bugs or incomplete feature coverage
4. **Performance**: No overhead from parsing and translating AWK programs
5. **Familiarity**: Users can leverage existing AWK knowledge directly

== Quick Start

To use the AWK converter, simply use AWK commands as you normally would. The converter will automatically handle the translation:

[source,nu]
----
# Basic field extraction
awk '{ print $1 }' data.txt

# Field separator
awk -F: '{ print $1 }' /etc/passwd

# Pattern matching
awk '/error/ { print $0 }' log.txt

# BEGIN/END blocks
awk 'BEGIN { print "Processing..." } { count++ } END { print "Total:", count }' data.txt
----

== Implementation

The AWK converter is implemented in `src/plugin/sus/awk.rs` and follows the standard converter pattern used throughout the nu-posix plugin.

=== Key Features

- **External Command Execution**: Uses the `^awk` syntax to run AWK as an external command
- **Proper Argument Quoting**: Automatically quotes arguments that contain spaces or special characters
- **Full AWK Compatibility**: Preserves all AWK functionality since it runs the actual AWK interpreter
- **Simple Integration**: Fits seamlessly into the existing converter registry system
- **Pipeline Compatible**: Works with Nu's pipeline system for data flow

=== Core Structure

The AWK converter follows the standard converter pattern:

[source,rust]
----
pub struct AwkConverter;

impl CommandConverter for AwkConverter {
    fn convert(&self, args: &[String]) -> Result<String> {
        let base = BaseConverter;

        if args.is_empty() {
            return Ok("^awk".to_string());
        }

        let mut result = String::from("^awk");
        for arg in args {
            result.push(' ');
            result.push_str(&base.quote_arg(arg));
        }

        Ok(result)
    }

    fn command_name(&self) -> &'static str {
        "awk"
    }

    fn description(&self) -> &'static str {
        "Runs awk as an external command with proper argument handling"
    }
}
----

=== Argument Processing

The converter handles all AWK arguments uniformly:

1. **Empty Commands**: `awk` → `^awk`
2. **Script Arguments**: Automatically quoted if they contain spaces or special characters
3. **Flag Arguments**: Passed through unchanged (`-F`, `-v`, `-f`, etc.)
4. **File Arguments**: Quoted if necessary for file paths with spaces

The converter follows this process:

1. **Input Validation**: Checks if arguments are provided
2. **Command Prefix**: Prepends `^awk` to indicate external command execution
3. **Argument Quoting**: Uses `BaseConverter::quote_arg()` to properly quote arguments containing:
   - Spaces
   - Special characters (`$`, `*`, `?`)
   - Quote characters (automatically escaped)
4. **Output Generation**: Joins all arguments with spaces

=== Quoting Logic

The converter uses the `BaseConverter::quote_arg()` method which:

* **Identifies Special Characters**: Spaces, `$`, `*`, `?` trigger quoting
* **Escapes Quotes**: Internal quotes are escaped with backslashes
* **Preserves Functionality**: Ensures arguments are passed correctly to AWK

The converter applies intelligent quoting:

- Simple arguments: `hello` → `hello`
- Arguments with spaces: `hello world` → `"hello world"`
- Arguments with quotes: `print "test"` → `"print \"test\""`
- Arguments with variables: `{ print $1 }` → `"{ print $1 }"`

== Conversion Examples

The converter handles various AWK command patterns:

=== Basic Usage

[source,nu]
----
# Input:  awk '{ print $1 }'
# Output: ^awk "{ print $1 }"

# Input:  awk 'NR > 1 { print $2 }' file.txt
# Output: ^awk "NR > 1 { print $2 }" file.txt

# Print first field
awk '{ print $1 }'
# Converts to:
^awk "{ print $1 }"

# Print with file input
awk '{ print $1 }' file.txt
# Converts to:
^awk "{ print $1 }" file.txt
----

=== Field Separators

[source,nu]
----
# Input:  awk -F: '{ print $1 }' /etc/passwd
# Output: ^awk -F : "{ print $1 }" /etc/passwd

# Input:  awk -F, '{ print $2 }' data.csv
# Output: ^awk -F , "{ print $2 }" data.csv

# Using colon as field separator
awk -F: '{ print $1 }' /etc/passwd
# Converts to:
^awk -F : "{ print $1 }" /etc/passwd

# Using comma separator
awk -F, '{ print $2 }' data.csv
# Converts to:
^awk -F , "{ print $2 }" data.csv
----

=== Variables and Options

[source,nu]
----
# Input:  awk -v OFS=, '{ print $1, $2 }'
# Output: ^awk -v OFS=, "{ print $1, $2 }"

# Input:  awk -v count=0 '{ count++ } END { print count }'
# Output: ^awk -v count=0 "{ count++ } END { print count }"

# Setting output field separator
awk -v OFS=, '{ print $1, $2 }'
# Converts to:
^awk -v OFS=, "{ print $1, $2 }"

# Custom variable
awk -v var=value '{ print var, $1 }'
# Converts to:
^awk -v var=value "{ print var, $1 }"
----

=== Script Files

[source,nu]
----
# Input:  awk -f script.awk data.txt
# Output: ^awk -f script.awk data.txt

# Input:  awk -f process.awk -v debug=1 input.txt
# Output: ^awk -f process.awk -v debug=1 input.txt

# Using script file
awk -f script.awk data.txt
# Converts to:
^awk -f script.awk data.txt
----

=== Complex Patterns

[source,nu]
----
# Input:  awk '/pattern/ { print $0 }'
# Output: ^awk "/pattern/ { print $0 }"

# Input:  awk 'BEGIN { FS=":" } /root/ { print $1 }' /etc/passwd
# Output: ^awk "BEGIN { FS=\":\" } /root/ { print $1 }" /etc/passwd

# Pattern matching
awk '/pattern/ { print $0 }'
# Converts to:
^awk "/pattern/ { print $0 }"

# BEGIN/END blocks
awk 'BEGIN { print "start" } { print NR, $0 } END { print "end" }'
# Converts to:
^awk "BEGIN { print \"start\" } { print NR, $0 } END { print \"end\" }"

# Numeric processing
awk '/^[0-9]+$/ { sum += $1 } END { print sum }'
# Converts to:
^awk "/^[0-9]+$/ { sum += $1 } END { print sum }"
----

=== Regular Expressions

[source,nu]
----
# Input:  awk '/^[0-9]+$/ { sum += $1 } END { print sum }'
# Output: ^awk "/^[0-9]+$/ { sum += $1 } END { print sum }"

# Input:  awk '$1 ~ /^[A-Z]/ { print $1 }'
# Output: ^awk "$1 ~ /^[A-Z]/ { print $1 }"
----

== Integration with Nu Shell

=== Pipeline Usage

The AWK converter works seamlessly with Nu's pipeline system:

[source,nu]
----
# AWK output piped to Nu commands
^awk '{ print $1 }' data.txt | where $it != "" | sort

# Nu data piped to AWK
ls | to csv | ^awk -F, '{ print $1, $3 }'

# Complex pipeline with multiple stages
open log.txt | lines | ^awk '/ERROR/ { print $0 }' | length

# Complex pipeline integration
open data.csv | to csv | ^awk -F, '{ print $2 }' | lines | each { |line| $line | str trim }
----

=== Data Flow Examples

[source,nu]
----
# Process CSV data
open data.csv | ^awk -F, '{ print $1, $3 }' | save processed.txt

# Log analysis
^awk '/ERROR/ { print $4, $5 }' /var/log/app.log | sort | uniq

# Text processing with Nu post-processing
^awk '{ print length($0), $0 }' file.txt | sort -n | first 10
----

=== Data Type Handling

Since AWK operates on text streams, integration considerations include:

* **Input Conversion**: Nu structured data may need conversion to text format
* **Output Processing**: AWK text output can be processed by Nu commands
* **Type Preservation**: Numeric data may need explicit conversion

== Registration

The AWK converter is registered in the `CommandRegistry` in `src/plugin/sus/mod.rs`:

[source,rust]
----
// Module declaration
pub mod awk;

// Re-export
pub use awk::AwkConverter;

// Registration in CommandRegistry::new()
registry.register(Box::new(AwkConverter));
----

== Testing

The implementation includes comprehensive tests covering various scenarios:

=== Test Coverage

- **Basic Functionality**: Empty commands, simple programs
- **Flag Handling**: `-F`, `-v`, `-f` options
- **Complex Patterns**: Regular expressions, BEGIN/END blocks
- **Special Characters**: Quotes, spaces, escape sequences
- **Registry Integration**: Command lookup

=== Test Implementation

The AWK converter includes comprehensive tests:

[source,rust]
----
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_awk_converter() {
        let converter = AwkConverter;

        // Empty awk
        assert_eq!(converter.convert(&[]).unwrap(), "^awk");

        // Simple program
        assert_eq!(
            converter.convert(&["{ print $1 }".to_string()]).unwrap(),
            "^awk \"{ print $1 }\""
        );

        // Field separator
        assert_eq!(
            converter.convert(&[
                "-F".to_string(),
                ":".to_string(),
                "{ print $1 }".to_string()
            ]).unwrap(),
            "^awk -F : \"{ print $1 }\""
        );
    }
}
----

=== Test Categories

1. **Basic Operations**: Simple AWK programs and file processing
2. **Flag Handling**: Various AWK command-line options
3. **Quoting Behavior**: Proper handling of special characters
4. **Complex Patterns**: Advanced AWK constructs and scripts
5. **Registry Integration**: Verification of command routing

== Performance Considerations

=== Execution Overhead

The external command approach has performance implications:

* **Process Creation**: Each AWK invocation creates a new process
* **Data Transfer**: Large datasets may have I/O overhead
* **Memory Usage**: AWK's memory management is separate from Nu

=== Optimization Strategies

1. **Batch Processing**: Process multiple files in single AWK invocation
2. **Pipeline Optimization**: Minimize data conversion between formats
3. **Caching**: Reuse AWK processes for repeated operations (future enhancement)

== Best Practices

=== When to Use AWK

AWK is particularly well-suited for:

* **Field-based Processing**: Column-oriented data manipulation
* **Pattern Matching**: Complex text pattern recognition
* **Mathematical Operations**: Numeric calculations on structured text
* **Report Generation**: Formatted output from structured data

=== Integration Patterns

Effective AWK integration patterns:

[source,nu]
----
# Data preparation
open data.csv | to csv | save temp.csv
^awk -F, '{ print $1, $2 }' temp.csv | from csv

# Result processing
^awk '{ print $1 }' data.txt | lines | each { |line| $line | str trim }

# Pipeline combination
ls *.txt | get name | each { |file| ^awk '{ print FILENAME, $0 }' $file }
----

== Limitations

=== Current Limitations

1. **No Native Integration**: Cannot access Nu's structured data directly
2. **Text-based Interface**: All data exchange happens through text streams
3. **Process Boundaries**: No shared memory or variable access
4. **Error Handling**: AWK errors are not integrated with Nu's error system

=== Future Enhancements

Potential improvements include:

1. **Smart Piping**: Detect pipeline patterns and optimize data flow
2. **Error Integration**: Better error message handling and propagation
3. **Tab Completion**: AWK-specific command completion
4. **Documentation**: Integration with Nu's help system

== Migration from Legacy

=== Previous Implementation

The legacy AWK converter had limited functionality:

* Only handled basic print statements
* No comprehensive flag support
* Limited argument quoting
* Incomplete conversion logic

=== New Implementation Benefits

The new SUS-based implementation provides:

* **Full AWK Support**: All AWK features preserved
* **Proper Argument Handling**: Comprehensive quoting and escaping
* **Registry Integration**: Consistent with other converters
* **Comprehensive Testing**: Extensive test coverage
* **Documentation**: Clear usage examples and guidance

== Conclusion

The AWK converter demonstrates that sometimes the best translation is no translation at all. By running AWK as an external command with proper argument handling, the converter provides 100% compatibility while maintaining the simplicity and reliability that users expect.

This approach serves as a model for other complex tools that resist direct translation, showing that pragmatic solutions can be more effective than ambitious but incomplete conversions.

The AWK converter successfully bridges the gap between POSIX shell scripts and Nushell, enabling users to leverage AWK's powerful text processing capabilities within Nu's modern shell environment.
